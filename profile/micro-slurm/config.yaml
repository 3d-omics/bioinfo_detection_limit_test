# This profile asumes slurm and that the reads to quantify are hundreds to thousands
# but very small
---
__use_yte__: true


executor: slurm
latency-wait: 60
use-conda: true
rerun-incomplete: true
keep-going: false

default-resources:
    runtime: 5m
    mem_mb: 1024


set-threads:
    # preprocess
    preprocess__fastp: 8
    preprocess__bowtie2__build: 24
    preprocess__bowtie2__map: 24
    preprocess__bowtie2__fastq: 24
    preprocess__bowtie2__clean: 24
    preprocess__kraken2__assign: 8
    # quantify
    quantify__mags: 8
    quantify__bowtie2__build: 24
    quantify__bowtie2__map: 24


set-resources:
    # preprocess
    preprocess__fastp:
        mem_mb: 8 * 1024
        runtime: 10 * 2 ** (attempt - 1)
    preprocess__bowtie2__build:
        mem_mb: 32 * 1024 * 2 ** (attempt - 1)
        runtime: 12 * 2 ** (attempt - 1)
    preprocess__bowtie2__map:
        mem_mb: 32 * 1024 * 2 ** (attempt - 1)
        runtime: 60 * 2 ** (attempt - 1)
    preprocess__bowtie2__fastq:
        mem_mb: 8 * 1024
        runtime: 30
    preprocess__nonpareil__run:
        mem_mb: 4 * 1024
        runtime: 30 * 2 ** (attempt - 1)
    preprocess__singlem__pipe:
        mem_mb: 8G
        runtime: 30 * 2 ** (attempt - 1)
    preprocess__multiqc:
        mem_mb: 8 * 1024 * 2 ** (attempt - 1)
        runtime: 2h
    # quantify
    quantify__bowtie2__build:
        mem_mb: 32 * 1024 * 2 ** (attempt - 1)
        runtime: 12h
    quantify__bowtie2__map:
        mem_mb: 32 * 1024
        runtime: 30 * 2 ** (attempt - 1)
    quantify__coverm__genome__aggregate:
        mem_mb: 8G
        runtime: 10m
    quantify__coverm__contig__aggregate:
        mem_mb: 8G
        runtime: 10m
    quantify__multiqc:
        mem_mb: 8 * 1024 * 2 ** (attempt - 1)
        runtime: 1h
